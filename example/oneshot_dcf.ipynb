{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c095107f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pasteur/appa/homes/ahabis/miniconda3/envs/scribble/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/pasteur/appa/homes/ahabis/miniconda3/envs/scribble/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/local/scratch/tmp/ipykernel_1160442/3382141517.py:10: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys \n",
    "path_dcf = str(Path(os.path.abspath('.')).resolve().parent)\n",
    "sys.path.append(path_dcf)\n",
    "from config import *\n",
    "from algorithms.oneshot_dcf import DCF\n",
    "from utils import *\n",
    "from algorithms.utils_dilated_tubules import *\n",
    "import pandas as pd\n",
    "import tifffile\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ca392e",
   "metadata": {},
   "source": [
    "## Choose a Slide from the dataset and a dilated tubule from the given slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d5d60ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_slide = 1\n",
    "nb_support_dilated_tubule = 8\n",
    "nb_query_dilated_tubule = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d1b813",
   "metadata": {},
   "source": [
    "### Instanciate the object DCF one-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ec27f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pasteur/appa/homes/ahabis/miniconda3/envs/scribble/lib/python3.9/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3549.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "dcf = DCF(n_epochs=100,\n",
    "            nb_augment=100,\n",
    "            isolines=np.array([0.0, 1.0]),\n",
    "            learning_rate=0.,\n",
    "            clip=1e-1,\n",
    "            sigma=5,\n",
    "            weights=0.9,\n",
    "            exponential_decay=0.999,\n",
    "            thresh=1e-2,\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c6ecace1",
   "metadata": {},
   "source": [
    "### Show the Support dilated tubule and the annotation of the support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a020439",
   "metadata": {},
   "outputs": [],
   "source": [
    "pentagon_coords = torch.tensor([[\n",
    "    [[1.0, 0.0],            # Vertex 1\n",
    "     [0.309, 0.951],        # Vertex 2\n",
    "     [-0.809, 0.588],       # Vertex 3\n",
    "     [-0.809, -0.588],      # Vertex 4\n",
    "     [0.309, -0.951]]       # Vertex 5\n",
    "]])\n",
    "\n",
    "scaled_pentagon_coords = (pentagon_coords * 0.5) + 0.5\n",
    "scaled_pentagon_coords = scaled_pentagon_coords.view(1, 1, 5, 2)\n",
    "contour_support = scaled_pentagon_coords.cuda()\n",
    "numpy_array = contour_support.squeeze().cpu().detach().numpy()\n",
    "# plt.plot(numpy_array[:,0], numpy_array[:,1])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afca52ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "img_support = torch.randn(1*3*512*512).reshape((1,3,512,512)).cuda().to(torch.float32)\n",
    "print(img_support.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6b7f82",
   "metadata": {},
   "source": [
    "### Fit the one shot DCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "191a4477",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 76.17it/s]\n"
     ]
    }
   ],
   "source": [
    "dcf.fit(img_support,\n",
    "        contour_support,\n",
    "        augment = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0974f4",
   "metadata": {},
   "source": [
    "### Predict on the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "320efb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pasteur/appa/homes/ahabis/miniconda3/envs/scribble/lib/python3.9/site-packages/torch_contour/torch_contour.py:511: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:1040.)\n",
      "  smoothed_tensor = F.conv1d(out_moved_axis, self.kernel, padding=\"same\", groups=2)\n"
     ]
    }
   ],
   "source": [
    "# filename_img = row_to_filename(annotations.iloc[nb_query_dilated_tubule])\n",
    "# img_test = tifffile.imread(os.path.join(path_images,filename_img))\n",
    "# contour_init = contour_inits[filename_img]\n",
    "# contour_init = preprocess_contour(contour_init,img_test)\n",
    "contours, score, tots, energies = dcf.predict(img_support,\n",
    "                                               contour_support)\n",
    "# tots[tots == 0] = 1e100\n",
    "# x = np.argmin(tots)\n",
    "# contour_to_display = (np.expand_dims(contours[-1], 1)).astype(int)\n",
    "# new_img = cv2.drawContours((((img_test/np.max(img_test))*255).astype(np.uint8)).copy(),\n",
    "#                         [contour_to_display],\n",
    "#                         0,\n",
    "#                         color = 1,\n",
    "#                         thickness=2)\n",
    "# plt.imshow(new_img)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc3f130",
   "metadata": {},
   "source": [
    "### This cell save the images of the evolution of the contour over time in folder_images_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "cmap = matplotlib.cm.get_cmap('cool')\n",
    "\n",
    "colors = [cmap(u)[:-1] for u in np.linspace(0,1,dcf.n_epochs+1)]\n",
    "colors = (np.array(colors)*255).astype(np.int32).tolist()\n",
    "\n",
    "tots = []\n",
    "imgs = []\n",
    "\n",
    "for i, contour in enumerate(contours):\n",
    "\n",
    "    contour_to_display = (np.expand_dims(contour, 1)).astype(int)\n",
    "    \n",
    "    new_img = cv2.drawContours((((img_test/np.max(img_test))*255).astype(np.uint8)).copy(),\n",
    "                               [contour_to_display],\n",
    "                               0,\n",
    "                               color = colors[0],\n",
    "                               thickness=3)\n",
    "    plt.imsave(os.path.join('folder_images_paper',filename_img.split('.')[0]+'_'+str(i)+'.png'),new_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c358abf",
   "metadata": {},
   "source": [
    "### This cell plot the evolution of the energies by (isoline, scale) over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f111094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ener = np.squeeze(energies.cpu().detach().numpy())                                                \n",
    "# isolines = dcf.isolines.cpu().detach().numpy()\n",
    "# for scale in range(5):\n",
    "#     for index, isoline in enumerate(isolines):\n",
    "#         plt.plot(np.arange(dcf.n_epochs),ener[:,scale,index],label = 'isoline '+str(isoline))\n",
    "#     plt.title('evolution of the energies at scale: ' +str(scale+1))\n",
    "#     plt.xlabel('step')\n",
    "#     plt.ylabel('energie value')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81950e0",
   "metadata": {},
   "source": [
    "### This cell plot the repartition of the annotation over the different slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotations = pd.read_csv(os.path.join(path_annotations,'annotations.csv'), index_col=0)\n",
    "# annotations = annotations.replace(['dilated_tubule','fake_tubule'], [1,0])\n",
    "# dt_annotations = annotations[['image','term']].groupby('image').sum()\n",
    "# dt_annotations.columns = ['number of dilated tubules']\n",
    "# all_annotations = annotations[['image','term']].groupby('image').count()\n",
    "# all_annotations.columns = ['number of annotations']\n",
    "\n",
    "# dataset_stats = pd.concat([dt_annotations,all_annotations], axis = 1)\n",
    "# dataset_stats['number of false dilated_tubule'] = dataset_stats['number of annotations'] - dataset_stats['number of dilated tubules']\n",
    "# dataset_stats['image'] = dataset_stats.index\n",
    "# dataset_stats = dataset_stats.reset_index(drop = True)\n",
    "# dataset_stats['image'] = dataset_stats['image'].apply(lambda x: x.split('.')[0])\n",
    "# dataset_stats\n",
    "# # dataset_stats['image'] = dataset_stats.index.apply(lambda x : x.split('.')[0])\n",
    "\n",
    "# import pandas as pd\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# sns.set(font_scale=1)\n",
    "\n",
    "# plt.figure(figsize = (10,10))\n",
    "# # plotting columns\n",
    "\n",
    "# ax = sns.barplot(x=dataset_stats['image'],\n",
    "#                  y=dataset_stats['number of annotations'],\n",
    "#                  color = np.array([207,105,138])/255,\n",
    "#                  label = 'n° of annotations')\n",
    "\n",
    "# ax = sns.barplot(x=dataset_stats['image'],\n",
    "#                  y=dataset_stats['number of dilated tubules'],\n",
    "#                  color = np.array([137,44,80])/255,\n",
    "#                  label = 'n° of dilated tubules')\n",
    " \n",
    "# # renaming the axes\n",
    "# ax.set_xlabel(\"Slide\",fontsize = 20)\n",
    "# ax.set_ylabel(\"N° of instances\",fontsize = 20)\n",
    "# plt.legend(fontsize = 20)\n",
    "\n",
    "# # visualizing illustration\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
